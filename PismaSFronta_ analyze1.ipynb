{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree, objectify\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import pymorphy2 as pm\n",
    "import pandas as pdr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция, которая достает из XML нужные нам данные: год письма и текст письма\n",
    "\n",
    "def get_data(xml_file):\n",
    "    with open(xml_file, 'rb') as f:\n",
    "        xml = f.read()\n",
    "        root = objectify.fromstring(xml)\n",
    "\n",
    "        # извлекаем данные.\n",
    "        year = str(root.teiHeader.fileDesc.titleStmt.year)\n",
    "        for cld in root.getchildren():\n",
    "            for elem in cld.getchildren():\n",
    "                for i in elem.getchildren():\n",
    "                    text = str(i.text) \n",
    "    return year, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция, которая извлекает текст для w2v\n",
    "\n",
    "def get_text(xml_file):\n",
    "    with open(xml_file, 'rb') as f:\n",
    "        xml = f.read()\n",
    "        root = objectify.fromstring(xml)\n",
    "\n",
    "        for cld in root.getchildren():\n",
    "            for elem in cld.getchildren():\n",
    "                for i in elem.getchildren():\n",
    "                    text = str(i.text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\МОЯ ПАПКА\\УЧЕБА\\ВКР\\corpus_ver2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функциия, которая делит предложения на слова и превращает все в словарь\n",
    "\n",
    "def tokenize_text(texts):\n",
    "    texts = [[text for text in t.split()] for t in texts]\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "    print(dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\МОЯ ПАПКА\\УЧЕБА\\ВКР\\corpus_ver2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "583\n",
      "1236\n",
      "896\n",
      "443\n"
     ]
    }
   ],
   "source": [
    "#делим все файлы на пять категорий - по годам, создаем списки таких писем\n",
    "\n",
    "texts_by_year = []\n",
    "texts41 = []\n",
    "texts42 = []\n",
    "texts43 = []\n",
    "texts44 = []\n",
    "texts45 = []\n",
    "\n",
    "for i in os.listdir(): #3565 документов\n",
    "    year, text = get_data(i)\n",
    "    if year == '1941':\n",
    "        texts41.append(text)\n",
    "    if year == '1942':\n",
    "        texts42.append(text)\n",
    "    if year == '1943':\n",
    "        texts43.append(text)\n",
    "    if year == '1944':\n",
    "        texts44.append(text)\n",
    "    if year == '1945':\n",
    "        texts45.append(text)\n",
    "texts_by_year.append(texts41)\n",
    "texts_by_year.append(texts42)\n",
    "texts_by_year.append(texts43)\n",
    "texts_by_year.append(texts44)\n",
    "texts_by_year.append(texts45)\n",
    "print(len(texts41))\n",
    "print(len(texts42))\n",
    "print(len(texts43))\n",
    "print(len(texts44))\n",
    "print(len(texts45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# объединяем все письма в одну строку для каждой категории\n",
    "for i in texts_by_year:\n",
    "    i = ' '.join(i)\n",
    "    string_list.append(i)\n",
    "print(len(string_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46558\n",
      "133538\n",
      "258144\n",
      "161251\n",
      "82860\n"
     ]
    }
   ],
   "source": [
    "#разбиваем строки на слова - токены, считаем количество в каждом объединенном тексте\n",
    "for i in string_list:\n",
    "    text=re.split(r'\\W+', i)\n",
    "    print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "583\n",
      "1236\n",
      "896\n",
      "443\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Считаем частотность. Сначала уберем из текстов цифры, знаки препинания и служебные части речи.\n",
    "# Лемматизируем - приводим оставшиеся слова в начальную форму.\n",
    "# Эти слова объединяем опять в тексты писем в одну строку - это формат для словаря Gensim.\n",
    "# Формируем для каждого из текстов словарь, где ключ - слово, а значение - количестве его повторов в тексте.\n",
    "\n",
    "word_frequency = []\n",
    "lemmas_list = []\n",
    "for letters in texts_by_year:\n",
    "    try:\n",
    "        lemmas = []\n",
    "        vocab2 = {}\n",
    "        for let in letters:\n",
    "            let = re.sub(r\"\\d+\", \"\", let)\n",
    "            let = re.split(r'\\W+', let)\n",
    "            vocab = []\n",
    "            for i in let:\n",
    "                try:\n",
    "                    m=pm.MorphAnalyzer().parse(i)[0]\n",
    "                    if m not in stopwords.words('russian'):\n",
    "                        if m.tag.POS not in ['PREP', 'CONJ', 'PRCL', 'INTJ', 'NPRO']:\n",
    "                            m=m.normal_form\n",
    "                            vocab.append(m)\n",
    "                            if m not in vocab2:\n",
    "                                vocab2[m] = 1\n",
    "                            else:        \n",
    "                                vocab2[m] += 1\n",
    "                except:\n",
    "                    print('Ошибка анализатора')\n",
    "            vocab = ' '.join(vocab)\n",
    "            lemmas.append(vocab)\n",
    "        print(len(lemmas))\n",
    "        lemmas_list.append(lemmas)\n",
    "        word_frequency.append(vocab2)\n",
    "    except:\n",
    "        print('Ошибка')\n",
    "print(len(lemmas_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = []\n",
    "for i in lemmas_list:\n",
    "    i = ' '.join(i)\n",
    "    string_list.append(i)\n",
    "    \n",
    "#стринг лист - список из пяти строк. Каждая строка - лемматизированные тексты всех писем соотвествующего года с сохранением порядка слов в предложении. \n",
    "#Используется для Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#на всякий случай сохраним в файл\n",
    "\n",
    "ith open('strings_for_Gensim.txt', 'a', encoding='utf-8') as file:\n",
    "    for i in string_list:\n",
    "        file.write(\"%s\\n\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3941\n",
      "7488\n",
      "9477\n",
      "7544\n",
      "4922\n"
     ]
    }
   ],
   "source": [
    "#смотрим число лемм по годам\n",
    "for i in word_frequency:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#частотность записываем в файл\n",
    "table.to_csv('letters_word_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отсортируем слова каждого из текстов по числу повторений\n",
    "sorted_by_value = []\n",
    "for i in word_frequency:\n",
    "    sort = sorted(i.items(), key=lambda kv: kv[1])\n",
    "    sorted_by_value.append(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст № 1, 20 самых частых слов:\n",
      "('время', 162)\n",
      "('тот', 167)\n",
      "('ещё', 168)\n",
      "('один', 169)\n",
      "('год', 178)\n",
      "('наш', 184)\n",
      "('день', 189)\n",
      "('ваш', 191)\n",
      "('живой', 195)\n",
      "('свой', 214)\n",
      "('очень', 219)\n",
      "('получить', 223)\n",
      "('привет', 236)\n",
      "('дорогой', 266)\n",
      "('', 350)\n",
      "('письмо', 374)\n",
      "('писать', 381)\n",
      "('мой', 425)\n",
      "('весь', 611)\n",
      "('быть', 612)\n",
      "\n",
      "\n",
      "Текст № 2, 20 самых частых слов:\n",
      "('жизнь', 404)\n",
      "('твой', 406)\n",
      "('сейчас', 431)\n",
      "('день', 440)\n",
      "('дорогой', 445)\n",
      "('очень', 461)\n",
      "('привет', 503)\n",
      "('который', 529)\n",
      "('ещё', 532)\n",
      "('год', 544)\n",
      "('получить', 559)\n",
      "('один', 578)\n",
      "('', 602)\n",
      "('наш', 618)\n",
      "('свой', 664)\n",
      "('писать', 915)\n",
      "('мой', 920)\n",
      "('письмо', 1119)\n",
      "('весь', 1582)\n",
      "('быть', 1943)\n",
      "\n",
      "\n",
      "Текст № 3, 20 самых частых слов:\n",
      "('живой', 933)\n",
      "('ещё', 946)\n",
      "('который', 949)\n",
      "('сейчас', 995)\n",
      "('пока', 1003)\n",
      "('написать', 1025)\n",
      "('год', 1047)\n",
      "('один', 1049)\n",
      "('дорогой', 1225)\n",
      "('', 1294)\n",
      "('получить', 1337)\n",
      "('наш', 1358)\n",
      "('свой', 1374)\n",
      "('мама', 1379)\n",
      "('привет', 1409)\n",
      "('мой', 1818)\n",
      "('писать', 2278)\n",
      "('письмо', 2935)\n",
      "('весь', 3013)\n",
      "('быть', 3074)\n",
      "\n",
      "\n",
      "Текст № 4, 20 самых частых слов:\n",
      "('сейчас', 568)\n",
      "('год', 582)\n",
      "('жизнь', 583)\n",
      "('очень', 590)\n",
      "('живой', 602)\n",
      "('пока', 687)\n",
      "('один', 719)\n",
      "('получить', 733)\n",
      "('ваш', 838)\n",
      "('дорогой', 858)\n",
      "('наш', 876)\n",
      "('свой', 937)\n",
      "('', 942)\n",
      "('мама', 994)\n",
      "('привет', 1035)\n",
      "('мой', 1174)\n",
      "('писать', 1302)\n",
      "('письмо', 1642)\n",
      "('быть', 1830)\n",
      "('весь', 1888)\n",
      "\n",
      "\n",
      "Текст № 5, 20 самых частых слов:\n",
      "('время', 261)\n",
      "('мама', 263)\n",
      "('который', 266)\n",
      "('сейчас', 291)\n",
      "('получить', 306)\n",
      "('дорогой', 311)\n",
      "('ещё', 334)\n",
      "('год', 347)\n",
      "('один', 354)\n",
      "('привет', 366)\n",
      "('ваш', 380)\n",
      "('день', 380)\n",
      "('наш', 426)\n",
      "('свой', 443)\n",
      "('мой', 483)\n",
      "('писать', 502)\n",
      "('', 506)\n",
      "('письмо', 629)\n",
      "('весь', 984)\n",
      "('быть', 1007)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#выведем ТОП-20 \n",
    "for i in sorted_by_value:\n",
    "    print(f'Текст № {sorted_by_value.index(i)+1}, 20 самых частых слов:')\n",
    "    print('\\n'.join(map(str, i[-20:])))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'касаточка': 1, 'сознавать': 1, 'слёзка': 1, 'покатиться': 1, 'повидать': 1, 'сахара': 1, 'лесенко': 1, 'нанести': 1, 'варечка': 1, 'внизу': 1, 'стена': 1, 'гнутов': 1, 'сухоборский': 1, 'сибирский': 1, 'полати': 1, 'читаемый': 1, 'козёл': 1, 'варить': 1, 'незавидный': 1, 'комиссия': 1, 'вовик': 1, 'волнение': 1, 'боднары': 1, 'прорыв': 1, 'кузнецов': 1, 'миронов': 1, 'музочка': 1, 'показатель': 1, 'муза': 1, 'клаш': 1, 'черкнуть': 1, 'взамен': 1, 'платье': 1, 'курточка': 1, 'кепка': 1, 'майка': 1, 'вовсе': 1, 'лизончик': 1, 'лизочек': 1, 'кабинет': 1, 'феликс': 1, 'алейников': 1, 'зарваться': 1, 'побратал': 1, 'корош': 1, 'обрушить': 1, 'харьковский': 1, 'орловский': 1, 'парковый': 1, 'заиметь': 1, 'заходз': 1, 'чапаевец': 1, 'черниченко': 1, 'елисеев': 1, 'щербако': 1, 'вым': 1, 'балкуновое': 1, 'яшагин': 1, 'щербинина': 1, 'ряиновый': 1, 'ад': 1, 'внешне': 1, 'звёздочка': 1, 'расхлябать': 1, 'фимчатов': 1, 'лоскутов': 1, 'локов': 1, 'русанов': 1, 'гамолин': 1, 'хозяюшка': 1, 'лёнечка': 1, 'добром': 1, 'установиться': 1, 'анохин': 1, 'братуха': 1, 'яценко': 1, 'нишава': 1, 'лера': 1, 'лагерный': 1, 'пастила': 1, 'районный': 1, 'посёлок': 1, 'садов': 1, 'огородный': 1, 'иваусский': 1, 'поблагодарить': 1, 'юноша': 1, 'вселять': 1, 'бодрость': 1, 'служение': 1, 'пропустить': 1, 'стукан': 1, 'угодный': 1, 'эскадрилья': 1, 'загореться': 1, 'попытка': 1, 'выброситься': 1, 'парашют': 1, 'малый': 1, 'выпрыгнуть': 1}\n"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "for i in sorted_by_value:\n",
    "    for tpl in i[:20]:\n",
    "        d[tpl[0]] = tpl[1]\n",
    "print(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v 1051\n",
      "a 606\n",
      "n 1909\n",
      "v 2178\n",
      "a 1153\n",
      "n 3488\n",
      "v 2630\n",
      "a 1489\n",
      "n 4557\n",
      "v 2147\n",
      "a 1146\n",
      "n 3590\n",
      "v 1368\n",
      "a 737\n",
      "n 2372\n"
     ]
    }
   ],
   "source": [
    "#для каждой категории выбираем глаголы, рилагательные и существительные\n",
    "verbs=[]\n",
    "adjectives=[]\n",
    "nouns=[]\n",
    "for i in sorted_by_value:\n",
    "    v = {}\n",
    "    a = {}\n",
    "    n = {}\n",
    "    for word in i:\n",
    "        f=pm.MorphAnalyzer().parse(word[0])[0]\n",
    "        if f.tag.POS=='INFN' or f.tag.POS=='VERB':\n",
    "            v[word[0]] = word[1]\n",
    "        if f.tag.POS=='ADJF' or f.tag.POS=='ADJS':\n",
    "            a[word[0]] = word[1]\n",
    "        if f.tag.POS=='NOUN':\n",
    "            n[word[0]] = word[1]  \n",
    "    print('v', len(v))\n",
    "    print('a', len(a))\n",
    "    print('n', len(n))\n",
    "    verbs.append(v)\n",
    "    adjectives.append(a)\n",
    "    nouns.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраним эти списки в файлы\n",
    "\n",
    "table = pd.DataFrame(verbs)\n",
    "table = table.T\n",
    "table.to_csv('letters_verbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(adjectives)\n",
    "table = table.T\n",
    "table.to_csv('letters_adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(nouns)\n",
    "table = table.T\n",
    "table.to_csv('letters_nouns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Частотностные таблицы лежат в google-папке\n",
    "https://drive.google.com/drive/folders/1rV-7-3O8IX-IvG0R53yvtfrJpBAQqXJo\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
